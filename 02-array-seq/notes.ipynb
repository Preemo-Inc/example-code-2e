{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @mhaligowski 's notes on chapter 2\n",
    "\n",
    "> ðŸ§  TIL:\n",
    "> \n",
    ">  `str` and `bytes` were added in Python 3???\n",
    "\n",
    "There are to flavors of sequence types in Python's standard library:\n",
    "\n",
    "* container sequences can hold different types of data (`list`, `tuple`, `collections.deque`)\n",
    "* flat sequences can only hold one type of data (`str`, `bytes`, `bytearray`, `memoryview`, `array.array`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container sequences hold *references*, while flat sequences hold *values*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequence = [1, 2]\n",
    "print(f\"subsequence is {subsequence}\")\n",
    "\n",
    "container = ['a', 'b', subsequence]\n",
    "print(f\"container is {container}\")\n",
    "\n",
    "subsequence.append(3)\n",
    "print(f\"subsequence is {subsequence}\")\n",
    "print(f\"container is {container}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ðŸŽ“ TIL:\n",
    ">\n",
    "> Every Python object has headers, for example for `float`:\n",
    "> * `ob_refcnt` - reference count\n",
    "> * `ob_type` - type of the object (pointer)\n",
    "> * `ob_fval` - C `double` holding the `float` value\n",
    ">\n",
    "> Each field takes 8 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another distinction:\n",
    "* mutable (`list`, `bytearray`, `array.array`, `collections.deque`, `memoryview`),\n",
    "* immutable (`tuple`, `str`, `bytes`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `list`: mutable container\n",
    "\n",
    "_listcomps_ FTW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = '$Â¢Â£Â¥â‚¬Â¤'\n",
    "\n",
    "# Non-Python way\n",
    "codes = []\n",
    "for symbol in symbols:\n",
    "    codes.append(ord(symbol))\n",
    "\n",
    "# Pythonic way\n",
    "codes = [ ord(symbol) for symbol in symbols ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip:\n",
    "> Line breaks are ignored inside pairs of `[]`, `{}` or `()`. Not sure what they mean by that?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walrus operator??? `:=` - assignment expression. It assigns a value to a variable as part of a larger expression. It is also known as the *named expression*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "squares = [x**2 for x in x]\n",
    "print(squares)\n",
    "\n",
    "cubes = [ last:=x**3 for x in x ]\n",
    "print(cubes, last)\n",
    "\n",
    "for x in x:\n",
    "    while (last:=x**3 != 9):\n",
    "        print(\"hi\")\n",
    "\n",
    "print(last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cartesian product\n",
    "chessboard = [f'{letter}{digit}' for letter in 'ABCDEFGH' for digit in range(1, 9)]\n",
    "print(chessboard)\n",
    "\n",
    "# BONUS: Splitting with listcomps!\n",
    "print([chessboard[start:start+8] for start in range(0, len(chessboard), 8)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_gencomps_ are like _listcomps_, written with `()` instead of `[]`. They are generators, so they don't build lists, but instead produce values on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'white']\n",
    "sizes = ['S', 'M', 'L']\n",
    "for tshirt tshitrs (f'{c} {s}' for c in colors for s in sizes):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from typing import Iterator, List\n",
    "import os\n",
    "\n",
    "def generate_tar_bytes(\n",
    "    *, root_file_path: str, files: List[str], part_size_threshold: int\n",
    ") -> Iterator[bytes]:\n",
    "    total_bytes_written = 0\n",
    "    buffer = b\"\"\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root_file_path, file)\n",
    "        with open(file_path, \"rb\") as file_reader:\n",
    "            \"\"\"this is mostly from stdlib tarfile\"\"\"\n",
    "            tar_info = tarfile.TarInfo(file)\n",
    "            tar_info.size = os.path.getsize(file_path)\n",
    "            header_bytes = tar_info.tobuf()\n",
    "            total_bytes_written += len(header_bytes)\n",
    "            buffer += header_bytes\n",
    "            while file_reader.peek(1) != b\"\":\n",
    "                while (current_length := len(buffer)) >= part_size_threshold:\n",
    "                    to_yield, buffer = (\n",
    "                        buffer[:part_size_threshold],\n",
    "                        buffer[part_size_threshold:],\n",
    "                    )\n",
    "                    yield to_yield\n",
    "                number_of_bytes_to_add = part_size_threshold - current_length\n",
    "                buffer += file_reader.read(number_of_bytes_to_add)\n",
    "            blocks, remainder = divmod(tar_info.size, tarfile.BLOCKSIZE)\n",
    "            if remainder > 0:\n",
    "                buffer += tarfile.NUL * (tarfile.BLOCKSIZE - remainder)\n",
    "                blocks += 1\n",
    "            total_bytes_written += blocks * tarfile.BLOCKSIZE\n",
    "\n",
    "    finishing_bytes = tarfile.NUL * (tarfile.BLOCKSIZE * 2)\n",
    "    buffer += finishing_bytes\n",
    "    total_bytes_written += len(finishing_bytes)\n",
    "    blocks, remainder = divmod(total_bytes_written, tarfile.RECORDSIZE)\n",
    "    if remainder > 0:\n",
    "        filler_bytes = tarfile.NUL * (tarfile.RECORDSIZE - remainder)\n",
    "        buffer += filler_bytes\n",
    "        total_bytes_written += len(filler_bytes)\n",
    "    while len(buffer) > 0:\n",
    "        to_yield, buffer = (\n",
    "            buffer[:part_size_threshold],\n",
    "            buffer[part_size_threshold:],\n",
    "        )\n",
    "        yield to_yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_service/embeddings_service/main.py\n",
    "\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:\n",
    "    \"\"\"\n",
    "    This is a context manager which is used to download all models on startup.\n",
    "    \"\"\"\n",
    "    if ENV_MANAGER.enable_cloud_logging:\n",
    "        setup_google_cloud_logging(\n",
    "            logging_level=ENV_MANAGER.logging_level,\n",
    "            model_name=ENV_MANAGER.models_hf_hub_name,\n",
    "            model_revision=ENV_MANAGER.models_hf_hub_revision,\n",
    "        )\n",
    "    else:\n",
    "        setup_logging(\n",
    "            logging_level=ENV_MANAGER.logging_level,\n",
    "        )\n",
    "    create_model_directory(Path(ENV_MANAGER.models_root_path))\n",
    "\n",
    "    if ENV_MANAGER.enable_open_telemetry_metrics:\n",
    "        setup_otlp(\n",
    "            service_name=ENV_MANAGER.service_name,\n",
    "            endpoint=ENV_MANAGER.open_telemetry_endpoint,\n",
    "        )\n",
    "    elif ENV_MANAGER.enable_console_metrics:\n",
    "        setup_console(service_name=ENV_MANAGER.service_name)\n",
    "\n",
    "    app.state.model_downloader_provider = ModelDownloaderProvider(\n",
    "        models_root_path=ENV_MANAGER.models_root_path\n",
    "    )\n",
    "    model_downloader = app.state.model_downloader_provider.get_downloader()\n",
    "    model_path = await model_downloader.download(\n",
    "        model_name=ENV_MANAGER.models_hf_hub_name,\n",
    "        model_revision=ENV_MANAGER.models_hf_hub_revision,\n",
    "    )\n",
    "\n",
    "    # TODO(matehal@gradient.ai, 09/14/2023): This creates the Embedder for the model too. It can get\n",
    "    # _a little_ slow, and having all the embedders can get expensive. It might make sense to\n",
    "    # have an instance of the service per model and or revision, and pass the model name and revision\n",
    "    # through the app argument.\n",
    "    app.state.embedder_provider = EmbedderProvider(\n",
    "        device=ENV_MANAGER.device_type,\n",
    "        enable_ctranslate2_compilation=ENV_MANAGER.enable_ctranslate2_compilation,\n",
    "        enable_pytorch_compilation=ENV_MANAGER.enable_pytorch_compilation,\n",
    "        model_path=model_path,\n",
    "        num_workers=ENV_MANAGER.workers_count,\n",
    "    )\n",
    "\n",
    "    logger.info(\"Embedding service ready to start\")\n",
    "\n",
    "    yield\n",
    "\n",
    "    # This is being executed on shutdown.\n",
    "    app.state.embedder_provider.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_with_pattern_matching(seq):\n",
    "  match seq:\n",
    "    case (): return 0\n",
    "    case (head,): return head\n",
    "    case (head, *tail): return head + sum_with_pattern_matching(tail)\n",
    "    case _:\n",
    "      raise ValueError(\"Not a sequence\")\n",
    "    \n",
    "pattern_sum = sum_with_pattern_matching((10,))\n",
    "print(pattern_sum)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
